# 📚 캐시 메모리 (Cache Memory)

<br>

1. [캐시 메모리란](#1.-캐시-메모리란)
2. [Hit, Miss](#2.-hit,-miss)
3. [지역성](#3.-지역성)
4. [매핑 프로세스](#4.-매핑-프로세스)
5. [쓰기 정책](#5.-쓰기-정책)
6. [교체 알고리즘](#6.-교체-알고리즘)
7. [버퍼 메모리](#7.-버퍼-메모리)

<br>

## 1. 캐시 메모리란

<br>

![image](https://user-images.githubusercontent.com/55391944/147055190-6c784ffc-2d3d-44ae-a340-b4478087685f.png)


- 캐싱(Caching)

캐시를 이용해 컴퓨터의 처리 성능을 높이기 위한 기법

<br>

- 캐시 메모리(Cache memory)

속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

레지스터 다음으로 상위에 위치

CPU가 주기억장치에서 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시에 저장한 뒤 다음에 이용할 때 주기억장치가 아닌 캐시에서 먼저 가져오며 속도를 향상시킴

속도라는 장점을 얻지만, 용량이 적고 비용이 비싼 단점이 있음

주로 L1(Level 1 cache), L2, L3 캐시가 있고, L1부터 빠르게 접근, L1에 없으면 L2에 접근

L3는 있는 경우도 있고 없는 경우도 있음

<br>

- 듀얼코어 프로세서

![image](https://user-images.githubusercontent.com/55391944/147055233-fc79d957-8773-4a59-b892-d86f853084d6.png)

L1(, L2) : CPU 내부

L3(또는 L2) : CPU와 RAM사이 (코어들이 공유하는 캐시)

디스크 캐시 : RAM과 하드디스크 사이의 캐시

페이지 : 메인메모리와 하드디스크(보조기억장치) 사이의 전송단위. 한페이지는 하드디스크의 한 블록

<br>

#### 캐시 예시

> CPU core와 메모리 사이의 병목 현상 완화  
> 웹브라우저 캐시 파일은 하드디스크와 웹페이지 사이의 병목 현상을 완화

<br>

#### 메모리 계층 구조

> Register > Cache > Main memory(RAM) > Hard disk > Magnetic Tape


<br>

## 2. Hit, Miss

CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없으면 'Cache Miss'

요청한 데이터를 캐시메모리에서 찾을 확률을 적중률(hit ratio)이라 함

캐시메모리의 성능 = 적중률

> 적중률 = 캐시메모리의 적중횟수 / 전체메모리의 참조횟수

- 적중(hit) : 캐시메모리 데이터를 CPU레지스터에 복사

- 캐시 실패(miss)/메모리 적중 : 메모리의 데이터를 캐시에 복사하고 캐시의 복제된 내용을 CPU레지스터에 복사

- 캐시, 메모리 실패 : 보조기억장치에서 필요한 데이터를 메모리, 캐시, CPU레지스터에 복사

캐시메모리의 적중여부는 참조의 지역성 원리에 달려있음

<br>

### 캐시 Miss

1. Compulsory miss(Cold start miss)  
   해당 메모리 주소를 처음 불러서 나는 미스  
   block size를 늘려 해결 &rarr; miss penalty 증가  
   지역성을 사용해 사용될 block을 미리 가져와 해결

2. Conflict miss  
   direct나 set associate mapping에서 같은 부분을 번갈아 사용하며 발생하는 미스  
   fully associate로 바꿔 해결

3. Capacity miss  
   캐시메모리의 공간이 부족해서 나는 미스 (Conflict는 주소할당 문제, Capacity는 공간 문제)  
   캐시를 크게 해서 해결 &rarr; access time 증가, 파워 많이먹음


<br>

## 3. 지역성

- 참조의 지역성 Locality of reference(지역성의 원리 Principle of locality)

동일한 값 또는 해당 값에 관계된 스토리지 위치가 자주 액세스되는 특성

1. 공간적 지역성(spatial locality) : CPU가 참조한 데이터와 인접한 데이터 역시 참조될 가능성이 높다

2. 시간적 지역성(temporal locality) : CPU가 한번 참조한 데이터는 다시 참조할 가능성이 높다

3. 순차적 지역성(sequential locality) : 분기가 발생하지 않는한 명령어는 메모리에 저장된 순서대로 인출/실행 된다

지역성은 어디까지나 경향에 대한 것이므로 항상 캐시의 높은 적중률을 보장해주지는 않음


<br>

## 4. 매핑 프로세스

매핑 프로세스 : 주기억장치로부터 캐시메모리로 데이터를 전송하는 방법

<br>

1. 직접매핑 (Direct Mapping)

![image](https://user-images.githubusercontent.com/55391944/147055395-57f5bf8c-4e37-441a-817c-ca73038c7ece.png)


메인메모리를 일정크기의 블록으로 나누고 각 블록을 캐시의 정해진 위치에 매핑

간단하고 구현비용이 적지만 적중률이 낮음

> 캐시 위치 = (Block 주소) modulo (캐시 내에 존재하는 전체 캐시 블록 수)  
> Tag : 특정 계층이 Block이 요청한 워드와 일치하는지 알려주는 주소 정보를 담은 필드  
> Valid bit : 특정 계층에서 해당 Block이 유효한 데이터를 포함하는지 알려주는 필드

2. 연관매핑 (Fully Associative Mapping)

비어있는 캐시 메모리가 있으면 마음대로 저장

직접매핑의 단점을 보완한 방식이나, 모든 태그들을 병렬로 검사하기에 복잡하고 비용이 높다는 단점을 가지나 적중률이 높음

3. 세트-연관매핑 (Set-Associative Mapping)

직접매핑과 연관매핑의 장점

각 라인은 하나의 세트에 속하고, 세트번호를 통해 영역을 탐색해 병렬탐색을 줄임. 무작위로 위치하기에 직접매핑의 단점도 보완

세트안의 라인수에 따라 n-way 연관 매핑이라 함


<br>

## 5. 쓰기 정책

캐시에 저장된 데이터에 수정이 발생했을때, 수정 내용을 메인메모리에 갱신하기 위한 시기와 방법을 결정

- Write-Through  
  캐시에 쓰기 동작이 이뤄질때마다 캐시와 메인메모리를 동시에 갱신 &rarr; 걸리는 시간이 가장 길다

- Write-Back  
  캐시에 쓰기 동작이 이뤄지는 동안은 캐시의 내용만 갱신  
  캐시의 내용이 캐시로부터 제거될때 메인메모리에 복사

- Write-One  
  캐시에 쓰기 동작이 이뤄질때 한번만 기록하고 이후의 기록은 모두 무시


<br>

## 6. 교체 알고리즘

캐시에 빈공간이 없는 상태에서 메인 메모리부터 캐시 메모리에 복사될때 어떤 블록의 내용을 내릴것인지 결정하는 것

LRU 방식을 많이 사용

- Random  
  교체될 페이지 임의 선정  
  오버헤드가 적음

- FIFO(First In First Out)  
  캐시 내에 오래 있었던 페이지 교체  
  자주 사용되는 페이지가 교체될 우려

- LFU(Least Frequently Used)  
  사용 횟수가 가장 적은 페이지 교체  
  최근 적재된 페이지가 교체될 우려

- LRU(Least Recently Used)  
  가장 오랫동안 사용되지 않은 페이지 교체  
  time stamping에 의한 오버헤드 존재

- Optimal  
  향후 가장 참조되지 않을 페이지 교체  
  실현 불가능

- NUR(Not Used Recently)  
  참조비트와 수정비트로 미사용 페이지 교체  
  최근 사용되지 않은 페이지 교체

- SCR(Second Change Replacement)  
  최초 참조 비트 1로 셋팅, 1인경우 0으로 셋팅. 0인경우 교체  
  기회를 한번 더줌


<br>

## 7. 버퍼 메모리

### 캐시

캐시는 속도가 다른 두 장치사이에서 속도차이를 메워주는 장치

빠른 처리속도를 가진 기기에겐 미리 데이터를 준비해둠으로서, 느린 처리속도를 가진 기기에겐 처리할 데이터를 대신 받아둠으로서 효율을 높임

### 버퍼

버퍼는 컴퓨터의 주기억 장치와 주변장치 사이에서 데이터를 주고받을 때 정보를 임시로 기억해 두고 사용할 수 있는 공간

버퍼도 두 장치 속도가 차이날 때 사용하나 속도 향상을 위한것이 아니라, 빠른쪽에서 데이터가 느린쪽으로 보내질 때 데이터 손실을 막기 위해 쓰임

사용 후 데이터 폐기

> 예)  
> 키보드 &rarr; OS는 키보드에서 데이터가 들어오면 프로세스가 사용하길 기다리지 않고 버퍼에 넣어둔 후 다른일처리  
> 모니터 &rarr; 그래픽카드가 처리한 프레임데이터를 버퍼에 저장한후 화면을 출력

<br>

결과적으로 캐시도 넓은 의미로는 버퍼에 포함된다함

<br>

> 참고  
> http://www.mathcs.emory.edu/~cheung/Courses/355/Syllabus/8-cache/set-assoc.html > https://coding-factory.tistory.com/357
